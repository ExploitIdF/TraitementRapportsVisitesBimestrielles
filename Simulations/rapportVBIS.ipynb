{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation des rapports des visites bimestrielles et des interventions de maintenance annuelle des issues et des niches \n",
    "\n",
    "* Définition du calendier et des numéros d'OT (fermeturesJours.csv)\n",
    "* Production des rapports (absences aléatoires)\n",
    "* Upload des rapports sur le serveur\n",
    "\n",
    "Cette simulation permet de tester les choix qui sont faits sur la forme des rapports.  \n",
    "La simulation fournit un jeu de données pour développer les outils de traitement des données pour la visualisation des résultats.   \n",
    "\n",
    "Les fichiers des issues et des niches et les regroupements en fermetures sont fournis en entrée de ce processus.  \n",
    "Leur élaboration est traitée dans un autre repository : https://github.com/ExploitIdF/Referentiel_Tunnels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install -r requirements.txt\n",
    "import pandas as pd, numpy as np\n",
    "import glob, re,json,io,os\n",
    "from datetime import datetime, timedelta\n",
    "from time import sleep\n",
    "import plotly.graph_objects as go\n",
    "pd.options.display.max_colwidth = 100\n",
    "from numpy.random import random\n",
    "from numpy.random import choice\n",
    "rng = np.random.default_rng()\n",
    "from google.cloud import bigquery,storage\n",
    "project_id = 'tunnels-dirif'\n",
    "clientB = bigquery.Client(project_id)\n",
    "storageC=storage.Client(project_id)\n",
    "\n",
    "issues=pd.read_csv('https://raw.githubusercontent.com/ExploitIdF/Referentiel_Tunnels/refs/heads/main/issuesFermetures.csv')#[[  'Tatouage',   'Fermeture']]\n",
    "# ['CodeEx', 'PC', 'Tatouage', 'triCode', 'Fermeture']\n",
    "issues['OQ']=range(290)\n",
    "\n",
    "niches=pd.read_csv('https://raw.githubusercontent.com/ExploitIdF/Referentiel_Tunnels/refs/heads/main/niches/nichesFermetures.csv')#[[  'Tatouage',   'Fermeture']]\n",
    "# ['CodeEx', 'Tatouage', 'triCode', 'Sens', 'Fermeture']\n",
    "niches['OQ']=range(len(niches)) # 437\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programmation des dates de fermetures\n",
    "Pour chaque fermeture (i: 0-29) , on définit aléatoirement 6 dates ( k:0-5, aussi 'ordreVB') de visites bimestrielles (champ \"jour\").  \n",
    "Les dates sont identifiées par le  *jour de l'année* (dayofyear, 0-365).   \n",
    "On définit les *OTs père* (champ \"OTP\" : 456000+k*100+i  ). Les OTPs sont dans la plage 456000+456600  \n",
    "On simule que des visites bimestrielles ne sont pas faites ou sont faites, mais reportées.  \n",
    "Pour cela, on définit le champ 'faitFerm' avec les valeurs (OK : fait à la date programmée, RP: fait mais reporté 21 jours plus tard & KO: non fait).    \n",
    "Paramètres du calcul : ```tauxRéalisation & tauxReport```   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on reconstruit la liste des fermetures à partir du fichier des issues\n",
    "fermetures=issues['Fermeture'].value_counts()\n",
    "\n",
    "tauxRéalisation =0.9  # Probabilité que les visites d'une fermeture soient réalisées à une date, dont report\n",
    "tauxReport=0.1\n",
    "\n",
    "if False:  # le process étant aléatoire, le refaire tourner modifie les résultats\n",
    "  fermJours=[]\n",
    "  for k in range(6):\n",
    "    jfTmp=pd.Series([(5+k*8)*7+ int(random()*4)*7+int(random()*4) for i in range(lenFer)],index=fermetures.index,name='jour')\n",
    "    otTmp=pd.Series([456000+k*100+i for i in range(lenFer)],index=fermetures.index,name='OTP')\n",
    "    ordTmp=pd.Series( k,index=fermetures.index,name='ordreVB')\n",
    "    fermJours.append(pd.concat([jfTmp,otTmp,ordTmp],axis=1))\n",
    "  fermJours=pd.concat(fermJours).reset_index()\n",
    "  fermJours['faitFerm']=[choice(a=['OK','RP','KO'],p=[tauxRéalisation- tauxReport,tauxReport,1-tauxRéalisation]) for i in range(lenFer*6)]\n",
    "  fermJours.to_csv('fermJours.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visites d'issues et niches\n",
    "On crée la table des visites d'issues programmées `VisiteIssues`\n",
    "On associe aux issues les dates de leurs fermetures programmées .    \n",
    "On définit les OT fils (OTFs) des visites d'issues : ordreVB*800+indexIss+456600  \n",
    "On simule que lors d'une visites bimestrielles certaines issues ne donnent pas lieu à la transmission d'un rapport.   \n",
    "Pour cela, on définit le champ 'faitLocal' avec mes valeurs (True / False).  \n",
    "Paramètres du calcul : `tauxAbsenceIN`\n",
    "\n",
    "On crée la table des rapports de visites d'issues transmis (faits) `VisiteIssuesFt` en sélectionnant avec les champs ```faitFerm & faitLocal```    \n",
    "On définit l'horodate de transmission du rapport par une valeur aléatoire comprise entre jour + 23h et jour + 27h (jour+1 +3h)   \n",
    "Pour les visites reportées (``` faitLocal = 'RP' ```) on calcule une nouvelle horodate 21 jours plus tard (on aurait pu faire varier le report mais on a simplifié)   \n",
    "Enfin, on choisit aléatoirement un nom d'agent (il aurait été plus logique de choisir les agents au niveau de la fermeture mais c'est plus simple comme ça)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fermJours=pd.read_csv('fermJours.csv')  # ['Fermeture', 'jour', 'OTP', 'ordreVB', 'faitFerm']\n",
    "tauxAbsenceIN=0.05 # pour les visites d'une fermeture, taux d'issues sans production d'un rapport\n",
    "lenFer=len(fermJours['Fermeture'].unique() )\n",
    "if True:\n",
    "  VisiteIssues=issues.merge(fermJours,on='Fermeture', how='outer')\n",
    "  VisiteIssues['OTF']=VisiteIssues['ordreVB']*800+VisiteIssues['OQ']+456600\n",
    "  VisiteIssues['faitLocal']=[random()>tauxAbsenceIN for i in range(len(VisiteIssues))]\n",
    "  VisiteIssues['faitLocal']=(VisiteIssues['faitLocal'])&(VisiteIssues['faitFerm']!='KO')\n",
    "  \n",
    "  VisiteIssuesFt=VisiteIssues.copy()\n",
    "  VisiteIssuesFt['minute']=[int(random()*240) for i in range(len(VisiteIssuesFt))]\n",
    "  VisiteIssuesFt['HoroDate']=pd.to_datetime(\"24/\"+VisiteIssuesFt['jour'].astype(str)+\" 23\",format='%y/%j %H')+pd.to_timedelta(VisiteIssuesFt['minute']*60000000000) \n",
    "  VisiteIssuesFt.loc[VisiteIssuesFt['faitFerm']=='RP','HoroDate']=VisiteIssuesFt.loc[VisiteIssuesFt['faitFerm']=='RP','HoroDate']+pd.to_timedelta(21*24*60*60000000000)\n",
    "  VisiteIssuesFt['agent']=[choice(['Karl','Karen', 'Kim','Kamel','Kun']) for k in range(len(VisiteIssuesFt))]\n",
    "  VisiteIssuesFt=VisiteIssuesFt[[ 'OTF','CodeEx', 'Tatouage','agent','jour', 'HoroDate','Fermeture','ordreVB','faitFerm','faitLocal']].sort_values('OTF')\n",
    "  VisiteIssuesFt.to_csv('VisiteIssuesFt.csv',index=False)\n",
    "\n",
    "  VisiteNiches=niches.merge(fermJours,on='Fermeture', how='outer')\n",
    "  VisiteNiches['OTF']=VisiteNiches['ordreVB']*800+VisiteNiches['OQ']+456600 + 300\n",
    "  VisiteNiches['faitLocal']=[random()>tauxAbsenceIN for i in range(len(VisiteNiches))]\n",
    "  VisiteNiches['faitLocal']=(VisiteNiches['faitLocal'])&(VisiteNiches['faitFerm']!='KO')\n",
    "\n",
    "  VisiteNichesFt=VisiteNiches.copy()\n",
    "  VisiteNichesFt['minute']=[int(random()*240) for i in range(len(VisiteNichesFt))]\n",
    "  VisiteNichesFt['HoroDate']=pd.to_datetime(\"24/\"+VisiteNichesFt['jour'].astype(str)+\" 23\",format='%y/%j %H')+pd.to_timedelta(VisiteNichesFt['minute']*60000000000) \n",
    "  VisiteNichesFt.loc[VisiteNichesFt['faitFerm']=='RP','HoroDate']=VisiteNichesFt.loc[VisiteNichesFt['faitFerm']=='RP','HoroDate']+pd.to_timedelta(21*24*60*60000000000)\n",
    "  VisiteNichesFt['agent']=[choice(['Karl','Karen', 'Kim','Kamel','Kun']) for k in range(len(VisiteNichesFt))]\n",
    "  VisiteNichesFt[[ 'OTF','CodeEx', 'Tatouage','agent','jour', 'HoroDate','Fermeture','ordreVB','faitFerm','faitLocal']].to_csv('VisiteNichesFt.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture du tableau des points de contrôle initial. Ce format devrait changer ...\n",
    "vbIa=pd.read_csv('../_static/controleVB_IA.csv',encoding='UTF-8').iloc[:,1:]\n",
    "lstPC=vbIa['PointControle'].value_counts().reset_index()\n",
    "lstPC['ordrePC']=lstPC['PointControle'].str.split('.').apply(lambda x: x[0]).astype(int).astype(str).str.zfill(2) \n",
    "lstPC=lstPC.sort_values('ordrePC').reset_index(drop=True) #.set_index('ordrePC',drop=True)\n",
    "lstLst=[]\n",
    "for i in range(len(lstPC)) :\n",
    "  vbIi=vbIa[vbIa['PointControle']==lstPC.loc[i,'PointControle']]\n",
    "  lstCom=[]\n",
    "  for j in vbIi.index:\n",
    "    lstCom.append(vbIi.loc[j,'Note'][0]+'_'+vbIi.loc[j,'ResulControle'])\n",
    "  lstLst.append(sorted(lstCom, reverse=False))\n",
    "\n",
    "lstNbrResul=[len(ll) for ll in lstLst]\n",
    "lsP=[[round(.2/(i-1),3)]*(i-1) +[1-(i-1)*round(.2/(i-1),3)]    for i in lstNbrResul]\n",
    "lstLstR=[['R'+str(i) for i in range(j)] for j in lstNbrResul ]\n",
    "\n",
    "tabRC=[]\n",
    "for i in range(len(lstPC)) :\n",
    "  for j in range(lstNbrResul[i]) :\n",
    "    tabRC.append(['P'+ lstPC.loc[i,'ordrePC'], lstPC.loc[i,'PointControle'],lstLstR[i][j],lstLst[i][j],lsP[i][j]  ] )\n",
    "pd.DataFrame(tabRC,columns=['codePC','PC','codeRC', 'RC', 'Probab']).to_csv('controleVB_IS.csv',index=False)\n",
    "# Dans le futur, on devrait entrer directement une table de ce type.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des rapports\n",
    "On lit la table des point&résultats de contrôles et de  leurs probabilités.  \n",
    "On lit la liste des visites \"faites\".  \n",
    "On génère aléatoirement, pour chaque visite et chaque point de controle, un résultat de contrôle et un commentaire.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "controleVB_IS=pd.read_csv('controleVB_IS.csv')\n",
    "VisiteIssuesFt=pd.read_csv('VisiteIssuesFt.csv')  # visites d'issues faites\n",
    "VisiteIssuesFt['HoroDate']=pd.to_datetime( VisiteIssuesFt['HoroDate'],format='%Y-%m-%d %H:%M:%S')\n",
    "fermJours=pd.read_csv('fermJours.csv')\n",
    "ComAls=[x for x in  ['Commentaire Aléatoire0 Très compliqué !','Commentaire Aléatoire1 Comment faire ?',\n",
    "    'Commentaire Aléatoire2 Trop long à vous expliquer, on appelera le PCTT demain','Commentaire Aléatoire3 Trois choses à noter',\n",
    "                     'Commentaire Aléatoire4 Sans commentaire']]\n",
    "nbrVBF=len(VisiteIssuesFt)\n",
    "codePCs=controleVB_IS['codePC'].unique()\n",
    "nbrPC=len(codePCs)\n",
    "RCs=[list(controleVB_IS[controleVB_IS['codePC']==codeP]['codeRC']  ) for codeP in codePCs ] # listes des résultats de contrôle par point de contrôle \n",
    "PRBs=[list(controleVB_IS[controleVB_IS['codePC']==codeP]['Probab'] ) for codeP in codePCs ] # listes des probabilité des résultats de contrôle par point de contrôle \n",
    "nbrRCs=[len(x) for x in RCs ]\n",
    "\n",
    "lstRC=[]\n",
    "for k in range(nbrVBF): \n",
    "   for n in range(nbrPC):\n",
    "      lstRC.append([k,codePCs[n],choice(a=RCs[n],p=PRBs[n]),choice(ComAls) ])\n",
    "lstRC=pd.DataFrame(lstRC,columns=['indRap', 'PC','RC','Com'])\n",
    "lstRC.to_csv('lstRC.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcRcNiIA=pd.read_csv('https://raw.githubusercontent.com/ExploitIdF/TraitementRapportsVisitesBimestrielles/refs/heads/master/controleNichesIA.csv')\n",
    "pcNiVB=['P26', 'P27', 'P28', 'P29', 'P30']\n",
    "pcRcNiVB=pcRcNiIA[pcRcNiIA['codePC'].isin(pcNiVB)]\n",
    "\n",
    "VisiteNichesFt=pd.read_csv('VisiteNichesFt.csv')  # visites d'issues faites\n",
    "VisiteNichesFt['HoroDate']=pd.to_datetime( VVisiteNichesFt['HoroDate'],format='%Y-%m-%d %H:%M:%S')\n",
    "fermJours=pd.read_csv('fermJours.csv')\n",
    "ComAls=[x for x in  ['Commentaire Aléatoire0 Très compliqué !','Commentaire Aléatoire1 Comment faire ?',\n",
    "    'Commentaire Aléatoire2 Trop long à vous expliquer, on appelera le PCTT demain','Commentaire Aléatoire3 Trois choses à noter',\n",
    "                     'Commentaire Aléatoire4 Sans commentaire']]\n",
    "nbrVBF=len(VisiteNichesFt)\n",
    "nbrPC=len(pcNiVB)\n",
    "RCs=[list(pcRcNiIA[pcRcNiIA['codePC']==codeP]['codeRC']  ) for codeP in pcNiVB ] # listes des résultats de contrôle par point de contrôle \n",
    "PRBs=[list(pcRcNiIA[pcRcNiIA['codePC']==codeP]['Probab'] ) for codeP in pcNiVB ] # listes des probabilité des résultats de contrôle par point de contrôle \n",
    "nbrRCs=[len(x) for x in RCs ]\n",
    "\n",
    "lstRC=[]\n",
    "for k in range(nbrVBF): \n",
    "   for n in range(nbrPC):\n",
    "      lstRC.append([k,pcNiVB[n],choice(a=RCs[n],p=PRBs[n]),choice(ComAls) ])\n",
    "lstRC=pd.DataFrame(lstRC,columns=['indRap', 'PC','RC','Com'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codePC</th>\n",
       "      <th>PC</th>\n",
       "      <th>codeRC</th>\n",
       "      <th>RC</th>\n",
       "      <th>Probab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P26</td>\n",
       "      <td>26. Accessibilité des équipements</td>\n",
       "      <td>P26R0</td>\n",
       "      <td>2_Vacuité/accessibilité OK</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P26</td>\n",
       "      <td>26. Accessibilité des équipements</td>\n",
       "      <td>P26R1</td>\n",
       "      <td>0_Obstacles gênants ou empêchant l'accessibilité</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P27</td>\n",
       "      <td>27. Extincteurs</td>\n",
       "      <td>P27R0</td>\n",
       "      <td>2_Présence de deux extincteurs</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P27</td>\n",
       "      <td>27. Extincteurs</td>\n",
       "      <td>P27R1</td>\n",
       "      <td>2_Niche non équipée d'extincteurs</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P27</td>\n",
       "      <td>27. Extincteurs</td>\n",
       "      <td>P27R2</td>\n",
       "      <td>0_1 ou 2 extincteurs manquants</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P28</td>\n",
       "      <td>28. Poste d'appel d'ugence (PAU)</td>\n",
       "      <td>P28R0</td>\n",
       "      <td>2_Contrôle visuel OK</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P28</td>\n",
       "      <td>28. Poste d'appel d'ugence (PAU)</td>\n",
       "      <td>P28R1</td>\n",
       "      <td>2_Niche non équipée</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P28</td>\n",
       "      <td>28. Poste d'appel d'ugence (PAU)</td>\n",
       "      <td>P28R2</td>\n",
       "      <td>0_Présence d'anomalies</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P29</td>\n",
       "      <td>29. Eclairage niche</td>\n",
       "      <td>P29R0</td>\n",
       "      <td>2_Eclairage niche OK</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P29</td>\n",
       "      <td>29. Eclairage niche</td>\n",
       "      <td>P29R1</td>\n",
       "      <td>0_Eclairage niche absent/insuffisant</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P30</td>\n",
       "      <td>30. Poteaux/bornes d'incendie</td>\n",
       "      <td>P30R0</td>\n",
       "      <td>2_Contrôle visuel OK</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P30</td>\n",
       "      <td>30. Poteaux/bornes d'incendie</td>\n",
       "      <td>P30R1</td>\n",
       "      <td>2_Niche non équipée</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P30</td>\n",
       "      <td>30. Poteaux/bornes d'incendie</td>\n",
       "      <td>P30R2</td>\n",
       "      <td>0_Présence d'anomalies</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   codePC                                 PC codeRC  \\\n",
       "0     P26  26. Accessibilité des équipements  P26R0   \n",
       "1     P26  26. Accessibilité des équipements  P26R1   \n",
       "2     P27                    27. Extincteurs  P27R0   \n",
       "3     P27                    27. Extincteurs  P27R1   \n",
       "4     P27                    27. Extincteurs  P27R2   \n",
       "5     P28   28. Poste d'appel d'ugence (PAU)  P28R0   \n",
       "6     P28   28. Poste d'appel d'ugence (PAU)  P28R1   \n",
       "7     P28   28. Poste d'appel d'ugence (PAU)  P28R2   \n",
       "8     P29                29. Eclairage niche  P29R0   \n",
       "9     P29                29. Eclairage niche  P29R1   \n",
       "10    P30      30. Poteaux/bornes d'incendie  P30R0   \n",
       "11    P30      30. Poteaux/bornes d'incendie  P30R1   \n",
       "12    P30      30. Poteaux/bornes d'incendie  P30R2   \n",
       "\n",
       "                                                  RC  Probab  \n",
       "0                         2_Vacuité/accessibilité OK     0.8  \n",
       "1   0_Obstacles gênants ou empêchant l'accessibilité     0.2  \n",
       "2                     2_Présence de deux extincteurs     0.6  \n",
       "3                  2_Niche non équipée d'extincteurs     0.2  \n",
       "4                     0_1 ou 2 extincteurs manquants     0.2  \n",
       "5                               2_Contrôle visuel OK     0.6  \n",
       "6                                2_Niche non équipée     0.2  \n",
       "7                             0_Présence d'anomalies     0.2  \n",
       "8                               2_Eclairage niche OK     0.8  \n",
       "9               0_Eclairage niche absent/insuffisant     0.2  \n",
       "10                              2_Contrôle visuel OK     0.6  \n",
       "11                               2_Niche non équipée     0.2  \n",
       "12                            0_Présence d'anomalies     0.2  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcRcNiVB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoadJob<project=tunnels-dirif, location=US, id=2d706f09-a1c6-4977-9ba9-6d7c23d5582e>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importation de la table des visites faites dans BigQuery (4 secondes)\n",
    "\n",
    "client  = clientB\n",
    "dataset  = client.dataset('rapports_visites')\n",
    "table = dataset.table('VisiteIssuesFt0')\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[ bigquery.SchemaField(cl, bigquery.enums.SqlTypeNames.STRING) for cl in VisiteIssuesFt.columns],\n",
    "    write_disposition=\"WRITE_TRUNCATE\",\n",
    "       autodetect=False,\n",
    "    source_format=bigquery.SourceFormat.CSV\n",
    ")\n",
    "job = client.load_table_from_dataframe( VisiteIssuesFt, table, job_config=job_config)  \n",
    "job.result() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoadJob<project=tunnels-dirif, location=US, id=7f2712d2-0427-422e-be31-2f344a8d8b4a>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = dataset.table('lstRC0')\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[ bigquery.SchemaField(cl, bigquery.enums.SqlTypeNames.STRING) for cl in lstRC.columns],\n",
    "    write_disposition=\"WRITE_TRUNCATE\",\n",
    "       autodetect=False,\n",
    "    source_format=bigquery.SourceFormat.CSV\n",
    ")\n",
    "job = client.load_table_from_dataframe( lstRC, table, job_config=job_config)  \n",
    "job.result() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les cellules qui suivent correspondent à une ancienne implémentation qui est caduque a vu de cde qui précède.\n",
    "Conservé pour mémoire mais à reprendre entièrement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m lstRC\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nbrVBF): \n\u001b[1;32m----> 5\u001b[0m \u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnbrPC\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlstRC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43mPCs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRCs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPRBs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimuRapp\u001b[39m(ferm,\u001b[38;5;28mord\u001b[39m):\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def simuRapp(ferm,ord):\n",
    "    vst=VisiteIssues[(VisiteIssues['Fermeture']==ferm)&(VisiteIssues['ordreVB']==ord)].reset_index(drop=True)  \n",
    "    for k in range(len(vst)):\n",
    "        if random()<.95:\n",
    "            dateFichier= str(int((vst.loc[k,'HoroDate']-datetime(2024,1,1)).total_seconds()+1000*random()))\n",
    "            flNm='24-3/ISVB-'+ str(vst.loc[k,'OT'])+'-'+dateFichier+ '.json'\n",
    "            flSr='{\"Tatouage\":\"'+str(VisiteIssues.loc[k,'Tatouage'])+'\",'\n",
    "            flSr=flSr+'\"HoroDate\":\"'+str(VisiteIssues.loc[k,'HoroDate'])+'\",'\n",
    "            flSr=flSr+'\"Agent\":\"'+choice(['Karl','Karen', 'Kim','Kamel','Kun']) +'\"'\n",
    "            for n in range():\n",
    "                cn=controleVB_IS[controleVB_IS['codePC']== controleVB_IS['codePC'].unique()[n] ][['codeRC','Probab']]\n",
    "                flSr=flSr+',\"PC'+str(n)+'\":\"'+choice(a=list(cn['codeRC']),p=list(cn['Probab']))+'\"'+' ,\"CM'+str(n)+'\":\"'+choice(a=ComAls)+'\"'            \n",
    "            flSr=flSr+'}'\n",
    "            with open(flNm,'bw') as fl:\n",
    "                fl.write(flSr.encode('UTF8'))\n",
    "\n",
    "# Création des rapports par application de la fonction avec une probabilité d'omission\n",
    "repertoire ='24-3/'\n",
    "if True :\n",
    "    filenames = next(os.walk(repertoire), (None, None, []))[2]\n",
    "    for fl in filenames:\n",
    "        os.remove(repertoire + fl)\n",
    "\n",
    "    for ferm in list(VisiteIssues['Fermeture'].unique()):\n",
    "        for j in range(6):\n",
    "            if random()<0.5:\n",
    "                simuRapp(ferm,j)\n",
    "filenames = next(os.walk(repertoire), (None, None, []))[2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload des rapports sur le serveur Google Storage\n",
    "On vide le répertoire cible (Storage : issues-secours/rapports-visites/) et  on charge les fichiers avec une pause de 3 secondes \n",
    "pour tenir compte de l'import dans BQ par la fonction qui est déclenchée par le chargement.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On vide le répertoire cible (Storage : issues-secours/rapports-visites/) et on recharge les fichiers avec une pause de 3 seconde pour tenir compte de l'import dans BQ\n",
    "bucket = storageC.get_bucket('issues-secours')\n",
    "blobs = storageC.list_blobs(bucket)\n",
    "for blob in blobs:\n",
    "    if 'ISV' in blob.name:\n",
    "        blob.delete()\n",
    "\n",
    "for fl in filenames[:]:\n",
    "    blob = bucket.blob('rapports-visites/'+fl)\n",
    "    blob.upload_from_filename('24-3/'+ fl, if_generation_match= 0)\n",
    "    sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Tatouage', 'HoroDate', 'Agent', 'PC0', 'CM0', 'PC1', 'CM1', 'PC2', 'CM2', 'PC3', 'CM3', 'PC4', 'CM4', 'PC5', 'CM5', 'PC6', 'CM6', 'PC7', 'CM7', 'PC8', 'CM8', 'PC9', 'CM9', 'PC10', 'CM10', 'PC11', 'CM11', 'PC12', 'CM12', 'PC13', 'CM13', 'PC14', 'CM14'])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Liste des clés pour alimenter le schéma d'importation dans BQ\n",
    "name = 'rapports-visites/' +filenames[5]\n",
    "blob = bucket.blob(name)\n",
    "fileContent= (blob.download_as_string(client=None).decode())\n",
    "json.loads(fileContent).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de l'importation dans BQ pour la fonction logDepot\n",
    "client  = bigquery.Client()\n",
    "dataset  = client.dataset('rapports_visites')\n",
    "table = dataset.table('LogDepot')\n",
    "\n",
    "def format_schema(schema):\n",
    "        formatted_schema = []\n",
    "        for row in schema:\n",
    "            formatted_schema.append(bigquery.SchemaField(row,'STRING', 'NULLABLE'))\n",
    "        return formatted_schema\n",
    "lst_schema_VBIS = ['Tatouage', 'HoroDate', 'Agent', 'PC0', 'CM0', 'PC1', 'CM1', 'PC2', 'CM2', 'PC3', 'CM3', 'PC4', 'CM4', 'PC5', 'CM5', 'PC6', 'CM6', \n",
    "                  'PC7', 'CM7', 'PC8', 'CM8', 'PC9', 'CM9', 'PC10', 'CM10', 'PC11', 'CM11', 'PC12', 'CM12', 'PC13', 'CM13', 'PC14', 'CM14']\n",
    "\n",
    "\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.schema = format_schema(lst_schema_VBIS)\n",
    "flJson=json.loads(fileContent)\n",
    "stByt=','.join([flJson[k] for k in lst_schema_VBIS  ]).encode(\"utf-8\")\n",
    "job = client.load_table_from_file(io.BytesIO(stByt), table, job_config = job_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
