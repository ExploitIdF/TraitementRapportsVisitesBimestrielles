{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation des rapports des visites bimestrielles et des interventions de maintenance annuelle des issues et des niches \n",
    "\n",
    "* Définition du calendier et des numéros d'OT (fermeturesJours.csv)\n",
    "* Production des rapports (absences aléatoires)\n",
    "* Upload des rapports sur le serveur\n",
    "\n",
    "Cette simulation permet de tester les choix qui sont faits sur la forme des rapports.  \n",
    "La simulation fournit un jeu de données pour développer les outils de traitement des données pour la visualisation des résultats.   \n",
    "\n",
    "Les fichiers des issues et des niches et les regroupements en fermetures sont fournis en entrée de ce processus.  \n",
    "Leur élaboration est traitée dans un autre repository : https://github.com/ExploitIdF/Referentiel_Tunnels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install -r requirements.txt\n",
    "import pandas as pd, numpy as np\n",
    "import glob, re,json,io,os\n",
    "from datetime import datetime, timedelta\n",
    "from time import sleep\n",
    "import plotly.graph_objects as go\n",
    "pd.options.display.max_colwidth = 100\n",
    "from numpy.random import random\n",
    "from numpy.random import choice\n",
    "rng = np.random.default_rng()\n",
    "from google.cloud import bigquery,storage\n",
    "project_id = 'tunnels-dirif'\n",
    "clientB = bigquery.Client(project_id)\n",
    "storageC=storage.Client(project_id)\n",
    "\n",
    "issues=pd.read_csv('https://raw.githubusercontent.com/ExploitIdF/Referentiel_Tunnels/refs/heads/main/issuesFermetures.csv')#[[  'Tatouage',   'Fermeture']]\n",
    "# ['CodeEx', 'PC', 'Tatouage', 'triCode', 'Fermeture']\n",
    "issues['OQ']=range(290)\n",
    "\n",
    "niches=pd.read_csv('https://raw.githubusercontent.com/ExploitIdF/Referentiel_Tunnels/refs/heads/main/nichesFermetures.csv')#[[  'Tatouage',   'Fermeture']]\n",
    "# ['CodeEx', 'Tatouage', 'triCode', 'Sens', 'Fermeture']\n",
    "niches['OQ']=range(len(niches)) # 437\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programmation des dates de fermetures\n",
    "Pour chaque fermeture (i: 0-29) , on définit aléatoirement 6 dates ( k:0-5, aussi 'ordreVB') de visites bimestrielles (champ \"jour\").  \n",
    "Les dates sont identifiées par le  *jour de l'année* (dayofyear, 0-365).   \n",
    "On définit les *OTs père* (champ \"OTP\" : 456000+k*100+i  ). Les OTPs sont dans la plage 456000+456600  \n",
    "On simule que des visites bimestrielles ne sont pas faites ou sont faites, mais reportées.  \n",
    "Pour cela, on définit le champ 'faitFerm' avec les valeurs (OK : fait à la date programmée, RP: fait mais reporté 21 jours plus tard & KO: non fait).    \n",
    "Paramètres du calcul : ```tauxRéalisation & tauxReport```   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on reconstruit la liste des fermetures à partir du fichier des issues\n",
    "fermetures=issues['Fermeture'].value_counts()\n",
    "\n",
    "tauxRéalisation =0.9  # Probabilité que les visites d'une fermeture soient réalisées à une date, dont report\n",
    "tauxReport=0.1\n",
    "\n",
    "if False:  # le process étant aléatoire, le refaire tourner modifie les résultats\n",
    "  fermJours=[]\n",
    "  for k in range(6):\n",
    "    jfTmp=pd.Series([(5+k*8)*7+ int(random()*4)*7+int(random()*4) for i in range(lenFer)],index=fermetures.index,name='jour')\n",
    "    otTmp=pd.Series([456000+k*100+i for i in range(lenFer)],index=fermetures.index,name='OTP')\n",
    "    ordTmp=pd.Series( k,index=fermetures.index,name='ordreVB')\n",
    "    fermJours.append(pd.concat([jfTmp,otTmp,ordTmp],axis=1))\n",
    "  fermJours=pd.concat(fermJours).reset_index()\n",
    "  fermJours['faitFerm']=[choice(a=['OK','RP','KO'],p=[tauxRéalisation- tauxReport,tauxReport,1-tauxRéalisation]) for i in range(lenFer*6)]\n",
    "  fermJours.to_csv('fermJours.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visistes d'issues et niches\n",
    "On crée la table des visites d'issues programmées `VisiteIssues`\n",
    "On associe aux issues les dates de leurs fermetures programmées .    \n",
    "On définit les OT fils (OTFs) des visites d'issues : ordreVB*800+indexIss+456600  \n",
    "On simule que lors d'une visites bimestrielles certaines issues ne donnent pas lieu à la transmission d'un rapport.   \n",
    "Pour cela, on définit le champ 'faitLocal' avec mes valeurs (True / False).  \n",
    "Paramètres du calcul : `tauxAbsenceIN`\n",
    "\n",
    "On crée la table des rapports de visites d'issues transmis (faits) `VisiteIssuesFt` en sélectionnant avec les champs ```faitFerm & faitLocal```    \n",
    "On définit l'horodate de transmission du rapport par une valeur aléatoire comprise entre jour + 23h et jour + 27h (jour+1 +3h)   \n",
    "Pour les visites reportées (``` faitLocal = 'RP' ```) on calcule une nouvelle horodate 21 jours plus tard (on aurait pu faire varier le report mais on a simplifié)   \n",
    "Enfin, on choisit aléatoirement un nom d'agent (il aurait été plus logique de choisir les agents au niveau de la fermeture mais c'est plus simple comme ça)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               CodeEx  Tatouage triCode Sens Fermeture   OQ  jour  OTP  \\\n",
      "2580  DEF-NSY-023/DEF  L10.156R     ECH    Y       NaN   29   NaN  NaN   \n",
      "2581  ECH-NSY-401/DEF  L11.168V     ECH    E       NaN  174   NaN  NaN   \n",
      "2582          NS6/ITA  L11.557H     ITA    W       NaN  365   NaN  NaN   \n",
      "2583      NSW-001/TRI  L11.861U     NaN    W       NaN  412   NaN  NaN   \n",
      "2584      NSW-002/TRI  L11.862V     NaN    W       NaN  413   NaN  NaN   \n",
      "2585      NSY-001/TRI  L11.863W     NaN    Y       NaN  414   NaN  NaN   \n",
      "2586      NSY-002/TRI  L11.864X     NaN    Y       NaN  415   NaN  NaN   \n",
      "\n",
      "      ordreVB faitFerm  \n",
      "2580      NaN      NaN  \n",
      "2581      NaN      NaN  \n",
      "2582      NaN      NaN  \n",
      "2583      NaN      NaN  \n",
      "2584      NaN      NaN  \n",
      "2585      NaN      NaN  \n",
      "2586      NaN      NaN  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "time data \"24/51.0 23\" doesn't match format \"%y/%j %H\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m VisiteNichesFt\u001b[38;5;241m=\u001b[39mVisiteNiches\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     25\u001b[0m VisiteNichesFt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminute\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mint\u001b[39m(random()\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m240\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(VisiteNichesFt))]\n\u001b[0;32m---> 26\u001b[0m VisiteNichesFt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHoroDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m24/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mVisiteNichesFt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjour\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m 23\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43my/\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mj \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mH\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m+\u001b[39mpd\u001b[38;5;241m.\u001b[39mto_timedelta(VisiteNichesFt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminute\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60000000000\u001b[39m) \n\u001b[1;32m     27\u001b[0m VisiteNichesFt\u001b[38;5;241m.\u001b[39mloc[VisiteNichesFt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfaitFerm\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRP\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHoroDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mVisiteNichesFt\u001b[38;5;241m.\u001b[39mloc[VisiteNichesFt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfaitFerm\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRP\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHoroDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39mpd\u001b[38;5;241m.\u001b[39mto_timedelta(\u001b[38;5;241m21\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m24\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60000000000\u001b[39m)\n\u001b[1;32m     28\u001b[0m VisiteNichesFt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124magent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m[choice([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKarl\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKaren\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKim\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKamel\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKun\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(VisiteNichesFt))]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:1063\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1061\u001b[0m             result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[0;32m-> 1063\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_listlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:247\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[0;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[1;32m    245\u001b[0m unique_dates \u001b[38;5;241m=\u001b[39m unique(arg)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[0;32m--> 247\u001b[0m     cache_dates \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# GH#45319\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:433\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[1;32m    436\u001b[0m     arg,\n\u001b[1;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    442\u001b[0m )\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:467\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[1;32m    457\u001b[0m     arg,\n\u001b[1;32m    458\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    462\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[1;32m    464\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m     result, tz_out \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m         unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32mstrptime.pyx:501\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:451\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:583\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime._parse_with_format\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: time data \"24/51.0 23\" doesn't match format \"%y/%j %H\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "fermJours=pd.read_csv('fermJours.csv')  # ['Fermeture', 'jour', 'OTP', 'ordreVB', 'faitFerm']\n",
    "tauxAbsenceIN=0.05 # pour les visites d'une fermeture, taux d'issues sans production d'un rapport\n",
    "lenFer=len(fermJours['Fermeture'].unique() )\n",
    "if True:\n",
    "  VisiteIssues=issues.merge(fermJours,on='Fermeture', how='outer')\n",
    "  VisiteIssues['OTF']=VisiteIssues['ordreVB']*800+VisiteIssues['OQ']+456600\n",
    "  VisiteIssues['faitLocal']=[random()>tauxAbsenceIN for i in range(len(VisiteIssues))]\n",
    "  VisiteIssues['faitLocal']=(VisiteIssues['faitLocal'])&(VisiteIssues['faitFerm']!='KO')\n",
    "  \n",
    "  VisiteIssuesFt=VisiteIssues.copy()\n",
    "  VisiteIssuesFt['minute']=[int(random()*240) for i in range(len(VisiteIssuesFt))]\n",
    "  VisiteIssuesFt['HoroDate']=pd.to_datetime(\"24/\"+VisiteIssuesFt['jour'].astype(str)+\" 23\",format='%y/%j %H')+pd.to_timedelta(VisiteIssuesFt['minute']*60000000000) \n",
    "  VisiteIssuesFt.loc[VisiteIssuesFt['faitFerm']=='RP','HoroDate']=VisiteIssuesFt.loc[VisiteIssuesFt['faitFerm']=='RP','HoroDate']+pd.to_timedelta(21*24*60*60000000000)\n",
    "  VisiteIssuesFt['agent']=[choice(['Karl','Karen', 'Kim','Kamel','Kun']) for k in range(len(VisiteIssuesFt))]\n",
    "  VisiteIssuesFt=VisiteIssuesFt[[ 'OTF','CodeEx', 'Tatouage','agent','jour', 'HoroDate','Fermeture','ordreVB','faitFerm','faitLocal']].sort_values('OTF')\n",
    "  VisiteIssuesFt.to_csv('VisiteIssuesFt.csv',index=False)\n",
    "\n",
    "  VisiteNiches=niches.merge(fermJours,on='Fermeture', how='outer')\n",
    "  print(VisiteNiches[VisiteNiches['jour'].isna()])\n",
    "  VisiteNiches['OTF']=VisiteNiches['ordreVB']*800+VisiteNiches['OQ']+456600 + 300\n",
    "  VisiteNiches['faitLocal']=[random()>tauxAbsenceIN for i in range(len(VisiteNiches))]\n",
    "  VisiteNiches['faitLocal']=(VisiteNiches['faitLocal'])&(VisiteNiches['faitFerm']!='KO')\n",
    "\n",
    "  VisiteNichesFt=VisiteNiches.copy()\n",
    "  VisiteNichesFt['minute']=[int(random()*240) for i in range(len(VisiteNichesFt))]\n",
    "  VisiteNichesFt['HoroDate']=pd.to_datetime(\"24/\"+VisiteNichesFt['jour'].astype(str)+\" 23\",format='%y/%j %H')+pd.to_timedelta(VisiteNichesFt['minute']*60000000000) \n",
    "  VisiteNichesFt.loc[VisiteNichesFt['faitFerm']=='RP','HoroDate']=VisiteNichesFt.loc[VisiteNichesFt['faitFerm']=='RP','HoroDate']+pd.to_timedelta(21*24*60*60000000000)\n",
    "  VisiteNichesFt['agent']=[choice(['Karl','Karen', 'Kim','Kamel','Kun']) for k in range(len(VisiteNichesFt))]\n",
    "  VisiteNichesFt[[ 'OTF','CodeEx', 'Tatouage','agent','jour', 'HoroDate','Fermeture','ordreVB','faitFerm','faitLocal']].to_csv('VisiteNichesFt.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture du tableau des points de contrôle initial. Ce format devrait changer ...\n",
    "vbIa=pd.read_csv('../_static/controleVB_IA.csv',encoding='UTF-8').iloc[:,1:]\n",
    "lstPC=vbIa['PointControle'].value_counts().reset_index()\n",
    "lstPC['ordrePC']=lstPC['PointControle'].str.split('.').apply(lambda x: x[0]).astype(int).astype(str).str.zfill(2) \n",
    "lstPC=lstPC.sort_values('ordrePC').reset_index(drop=True) #.set_index('ordrePC',drop=True)\n",
    "lstLst=[]\n",
    "for i in range(len(lstPC)) :\n",
    "  vbIi=vbIa[vbIa['PointControle']==lstPC.loc[i,'PointControle']]\n",
    "  lstCom=[]\n",
    "  for j in vbIi.index:\n",
    "    lstCom.append(vbIi.loc[j,'Note'][0]+'_'+vbIi.loc[j,'ResulControle'])\n",
    "  lstLst.append(sorted(lstCom, reverse=False))\n",
    "\n",
    "lstNbrResul=[len(ll) for ll in lstLst]\n",
    "lsP=[[round(.2/(i-1),3)]*(i-1) +[1-(i-1)*round(.2/(i-1),3)]    for i in lstNbrResul]\n",
    "lstLstR=[['R'+str(i) for i in range(j)] for j in lstNbrResul ]\n",
    "\n",
    "tabRC=[]\n",
    "for i in range(len(lstPC)) :\n",
    "  for j in range(lstNbrResul[i]) :\n",
    "    tabRC.append(['P'+ lstPC.loc[i,'ordrePC'], lstPC.loc[i,'PointControle'],lstLstR[i][j],lstLst[i][j],lsP[i][j]  ] )\n",
    "pd.DataFrame(tabRC,columns=['codePC','PC','codeRC', 'RC', 'Probab']).to_csv('controleVB_IS.csv',index=False)\n",
    "# Dans le futur, on devrait entrer directement une table de ce type.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des rapports\n",
    "On lit la table des point&résultats de contrôles et leur probabilité.\n",
    "On lit la liste des visites \"faites\".\n",
    "On génère aléatoirement, pour chaque visite et chaque point de controle, un résultat de contrôle et un commentaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "controleVB_IS=pd.read_csv('controleVB_IS.csv')\n",
    "VisiteIssuesFt=pd.read_csv('VisiteIssuesFt.csv')  # visites d'issues faites\n",
    "VisiteIssuesFt['HoroDate']=pd.to_datetime( VisiteIssuesFt['HoroDate'],format='%Y-%m-%d %H:%M:%S')\n",
    "fermJours=pd.read_csv('fermJours.csv')\n",
    "ComAls=[x for x in  ['Commentaire Aléatoire0 Très compliqué !','Commentaire Aléatoire1 Comment faire ?',\n",
    "    'Commentaire Aléatoire2 Trop long à vous expliquer, on appelera le PCTT demain','Commentaire Aléatoire3 Trois choses à noter',\n",
    "                     'Commentaire Aléatoire4 Sans commentaire']]\n",
    "nbrVBF=len(VisiteIssuesFt)\n",
    "codePCs=controleVB_IS['codePC'].unique()\n",
    "nbrPC=len(codePCs)\n",
    "RCs=[list(controleVB_IS[controleVB_IS['codePC']==codeP]['codeRC']  ) for codeP in codePCs ] # listes des résultats de contrôle par point de contrôle \n",
    "PRBs=[list(controleVB_IS[controleVB_IS['codePC']==codeP]['Probab'] ) for codeP in codePCs ] # listes des probabilité des résultats de contrôle par point de contrôle \n",
    "nbrRCs=[len(x) for x in RCs ]\n",
    "\n",
    "lstRC=[]\n",
    "for k in range(nbrVBF): \n",
    "   for n in range(nbrPC):\n",
    "      lstRC.append([k,codePCs[n],choice(a=RCs[n],p=PRBs[n]),choice(ComAls) ])\n",
    "lstRC=pd.DataFrame(lstRC,columns=['indRap', 'PC','RC','Com'])\n",
    "lstRC.to_csv('lstRC.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indRap</th>\n",
       "      <th>PC</th>\n",
       "      <th>RC</th>\n",
       "      <th>Com</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>P01</td>\n",
       "      <td>R4</td>\n",
       "      <td>Commentaire Aléatoire4 Sans commentaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>P02</td>\n",
       "      <td>R9</td>\n",
       "      <td>Commentaire Aléatoire1 Comment faire ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>P03</td>\n",
       "      <td>R4</td>\n",
       "      <td>Commentaire Aléatoire1 Comment faire ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>P04</td>\n",
       "      <td>R5</td>\n",
       "      <td>Commentaire Aléatoire0 Très compliqué !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>P05</td>\n",
       "      <td>R2</td>\n",
       "      <td>Commentaire Aléatoire4 Sans commentaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22135</th>\n",
       "      <td>1475</td>\n",
       "      <td>P11</td>\n",
       "      <td>R2</td>\n",
       "      <td>Commentaire Aléatoire0 Très compliqué !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22136</th>\n",
       "      <td>1475</td>\n",
       "      <td>P12</td>\n",
       "      <td>R3</td>\n",
       "      <td>Commentaire Aléatoire0 Très compliqué !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22137</th>\n",
       "      <td>1475</td>\n",
       "      <td>P13</td>\n",
       "      <td>R1</td>\n",
       "      <td>Commentaire Aléatoire4 Sans commentaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22138</th>\n",
       "      <td>1475</td>\n",
       "      <td>P14</td>\n",
       "      <td>R2</td>\n",
       "      <td>Commentaire Aléatoire3 Trois choses à noter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22139</th>\n",
       "      <td>1475</td>\n",
       "      <td>P20</td>\n",
       "      <td>R0</td>\n",
       "      <td>Commentaire Aléatoire4 Sans commentaire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22140 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       indRap   PC  RC                                          Com\n",
       "0           0  P01  R4      Commentaire Aléatoire4 Sans commentaire\n",
       "1           0  P02  R9       Commentaire Aléatoire1 Comment faire ?\n",
       "2           0  P03  R4       Commentaire Aléatoire1 Comment faire ?\n",
       "3           0  P04  R5      Commentaire Aléatoire0 Très compliqué !\n",
       "4           0  P05  R2      Commentaire Aléatoire4 Sans commentaire\n",
       "...       ...  ...  ..                                          ...\n",
       "22135    1475  P11  R2      Commentaire Aléatoire0 Très compliqué !\n",
       "22136    1475  P12  R3      Commentaire Aléatoire0 Très compliqué !\n",
       "22137    1475  P13  R1      Commentaire Aléatoire4 Sans commentaire\n",
       "22138    1475  P14  R2  Commentaire Aléatoire3 Trois choses à noter\n",
       "22139    1475  P20  R0      Commentaire Aléatoire4 Sans commentaire\n",
       "\n",
       "[22140 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoadJob<project=tunnels-dirif, location=US, id=2d706f09-a1c6-4977-9ba9-6d7c23d5582e>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importation de la table des visites faites dans BigQuery (4 secondes)\n",
    "\n",
    "client  = clientB\n",
    "dataset  = client.dataset('rapports_visites')\n",
    "table = dataset.table('VisiteIssuesFt0')\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[ bigquery.SchemaField(cl, bigquery.enums.SqlTypeNames.STRING) for cl in VisiteIssuesFt.columns],\n",
    "    write_disposition=\"WRITE_TRUNCATE\",\n",
    "       autodetect=False,\n",
    "    source_format=bigquery.SourceFormat.CSV\n",
    ")\n",
    "job = client.load_table_from_dataframe( VisiteIssuesFt, table, job_config=job_config)  \n",
    "job.result() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoadJob<project=tunnels-dirif, location=US, id=7f2712d2-0427-422e-be31-2f344a8d8b4a>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = dataset.table('lstRC0')\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[ bigquery.SchemaField(cl, bigquery.enums.SqlTypeNames.STRING) for cl in lstRC.columns],\n",
    "    write_disposition=\"WRITE_TRUNCATE\",\n",
    "       autodetect=False,\n",
    "    source_format=bigquery.SourceFormat.CSV\n",
    ")\n",
    "job = client.load_table_from_dataframe( lstRC, table, job_config=job_config)  \n",
    "job.result() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les cellules qui suivent correspondent à une ancienne implémentation qui est caduque a vu de cde qui précède.\n",
    "Conservé pour mémoire mais à reprendre entièrement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m lstRC\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nbrVBF): \n\u001b[1;32m----> 5\u001b[0m \u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnbrPC\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlstRC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43mPCs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRCs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPRBs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimuRapp\u001b[39m(ferm,\u001b[38;5;28mord\u001b[39m):\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def simuRapp(ferm,ord):\n",
    "    vst=VisiteIssues[(VisiteIssues['Fermeture']==ferm)&(VisiteIssues['ordreVB']==ord)].reset_index(drop=True)  \n",
    "    for k in range(len(vst)):\n",
    "        if random()<.95:\n",
    "            dateFichier= str(int((vst.loc[k,'HoroDate']-datetime(2024,1,1)).total_seconds()+1000*random()))\n",
    "            flNm='24-3/ISVB-'+ str(vst.loc[k,'OT'])+'-'+dateFichier+ '.json'\n",
    "            flSr='{\"Tatouage\":\"'+str(VisiteIssues.loc[k,'Tatouage'])+'\",'\n",
    "            flSr=flSr+'\"HoroDate\":\"'+str(VisiteIssues.loc[k,'HoroDate'])+'\",'\n",
    "            flSr=flSr+'\"Agent\":\"'+choice(['Karl','Karen', 'Kim','Kamel','Kun']) +'\"'\n",
    "            for n in range():\n",
    "                cn=controleVB_IS[controleVB_IS['codePC']== controleVB_IS['codePC'].unique()[n] ][['codeRC','Probab']]\n",
    "                flSr=flSr+',\"PC'+str(n)+'\":\"'+choice(a=list(cn['codeRC']),p=list(cn['Probab']))+'\"'+' ,\"CM'+str(n)+'\":\"'+choice(a=ComAls)+'\"'            \n",
    "            flSr=flSr+'}'\n",
    "            with open(flNm,'bw') as fl:\n",
    "                fl.write(flSr.encode('UTF8'))\n",
    "\n",
    "# Création des rapports par application de la fonction avec une probabilité d'omission\n",
    "repertoire ='24-3/'\n",
    "if True :\n",
    "    filenames = next(os.walk(repertoire), (None, None, []))[2]\n",
    "    for fl in filenames:\n",
    "        os.remove(repertoire + fl)\n",
    "\n",
    "    for ferm in list(VisiteIssues['Fermeture'].unique()):\n",
    "        for j in range(6):\n",
    "            if random()<0.5:\n",
    "                simuRapp(ferm,j)\n",
    "filenames = next(os.walk(repertoire), (None, None, []))[2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload des rapports sur le serveur Google Storage\n",
    "On vide le répertoire cible (Storage : issues-secours/rapports-visites/) et  on charge les fichiers avec une pause de 3 secondes \n",
    "pour tenir compte de l'import dans BQ par la fonction qui est déclenchée par le chargement.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On vide le répertoire cible (Storage : issues-secours/rapports-visites/) et on recharge les fichiers avec une pause de 3 seconde pour tenir compte de l'import dans BQ\n",
    "bucket = storageC.get_bucket('issues-secours')\n",
    "blobs = storageC.list_blobs(bucket)\n",
    "for blob in blobs:\n",
    "    if 'ISV' in blob.name:\n",
    "        blob.delete()\n",
    "\n",
    "for fl in filenames[:]:\n",
    "    blob = bucket.blob('rapports-visites/'+fl)\n",
    "    blob.upload_from_filename('24-3/'+ fl, if_generation_match= 0)\n",
    "    sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Tatouage', 'HoroDate', 'Agent', 'PC0', 'CM0', 'PC1', 'CM1', 'PC2', 'CM2', 'PC3', 'CM3', 'PC4', 'CM4', 'PC5', 'CM5', 'PC6', 'CM6', 'PC7', 'CM7', 'PC8', 'CM8', 'PC9', 'CM9', 'PC10', 'CM10', 'PC11', 'CM11', 'PC12', 'CM12', 'PC13', 'CM13', 'PC14', 'CM14'])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Liste des clés pour alimenter le schéma d'importation dans BQ\n",
    "name = 'rapports-visites/' +filenames[5]\n",
    "blob = bucket.blob(name)\n",
    "fileContent= (blob.download_as_string(client=None).decode())\n",
    "json.loads(fileContent).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de l'importation dans BQ pour la fonction logDepot\n",
    "client  = bigquery.Client()\n",
    "dataset  = client.dataset('rapports_visites')\n",
    "table = dataset.table('LogDepot')\n",
    "\n",
    "def format_schema(schema):\n",
    "        formatted_schema = []\n",
    "        for row in schema:\n",
    "            formatted_schema.append(bigquery.SchemaField(row,'STRING', 'NULLABLE'))\n",
    "        return formatted_schema\n",
    "lst_schema_VBIS = ['Tatouage', 'HoroDate', 'Agent', 'PC0', 'CM0', 'PC1', 'CM1', 'PC2', 'CM2', 'PC3', 'CM3', 'PC4', 'CM4', 'PC5', 'CM5', 'PC6', 'CM6', \n",
    "                  'PC7', 'CM7', 'PC8', 'CM8', 'PC9', 'CM9', 'PC10', 'CM10', 'PC11', 'CM11', 'PC12', 'CM12', 'PC13', 'CM13', 'PC14', 'CM14']\n",
    "\n",
    "\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.schema = format_schema(lst_schema_VBIS)\n",
    "flJson=json.loads(fileContent)\n",
    "stByt=','.join([flJson[k] for k in lst_schema_VBIS  ]).encode(\"utf-8\")\n",
    "job = client.load_table_from_file(io.BytesIO(stByt), table, job_config = job_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
